{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a31a06d",
   "metadata": {},
   "source": [
    "## 1. Imports (Libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec9113",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d09a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9330d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735f845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLP libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41890203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1a5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445a9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-multilearn\n",
      "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
      "     ---------------------------------------- 0.0/89.4 kB ? eta -:--:--\n",
      "     --------------------------- ------------ 61.4/89.4 kB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 89.4/89.4 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-multilearn\n",
      "Successfully installed scikit-multilearn-0.2.0\n"
     ]
    }
   ],
   "source": [
    "#uncomment if not installed\n",
    "\n",
    "#!pip install scikit-multilearn\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bef4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45206534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some display adjustments to account for the fact that we have many columns\n",
    "# and some columns contain many characters\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6e1cb",
   "metadata": {},
   "source": [
    "## 2. Imports (Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c234c",
   "metadata": {},
   "source": [
    "<a id='data_imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099aa819",
   "metadata": {},
   "source": [
    "Since we exported the cleaned dataset as a csv file in Part II, we can simply import that file and start working on it immediately. The two columns we are most concerned with are 'redditlabel' and 'text_lemma'.\n",
    "\n",
    "Data dictionary:\n",
    "\n",
    "|column| datatype|explanation|\n",
    "|:-|:-:|:-|\n",
    "|<b>redditlabel</b>|*integer*| The numeric boolean representation of our two classes. 0 means Keto and 1 means Paleo.|\n",
    "|<b>title</b>| *string*| The subject title of the Reddit post.|\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('simpsons_10_tropes.csv')\n",
    "train_df = pd.read_csv('10_tropes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78df6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8271c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.set_index(['Trope Name'])['text_lemma'].str.split().apply(lambda x:  pd.Series([' '.join(x[i:i+ (len(x)//30)]) \n",
    "                                                                                         for i in range(0, len(x), len(x)//30)])).stack().reset_index().drop('level_1', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ed19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aac2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['Trope Name', 'text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = train_df['text_lemma']\n",
    "y = train_df['Trope Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f'The X train set is {X_train.shape[0]} rows long.')\n",
    "print(f'The y train set is {y_train.shape[0]} rows long.')\n",
    "print(f'The X test set is {X_test.shape[0]} rows long.')\n",
    "print(f'The y test set is {y_test.shape[0]} rows long.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "pipe_cv_lr = Pipeline(steps=[('cvec', CountVectorizer()),\n",
    "                               ('logreg', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "pipe_cv_lr_params = {'cvec__max_features':[5000], #2000, 3000, 4000, 5000\n",
    "                       'cvec__min_df':[3], #2, 3\n",
    "                       'cvec__max_df':[.85], #.85, .90, .95\n",
    "                       'cvec__ngram_range':[(1,2)], #(1,1), (1,2), (1,3), (2,2)\n",
    "                       'logreg__C': [0.1], #0.05, 0.1, 1\n",
    "                       'logreg__penalty': ['l2']} #'l1', 'l2'\n",
    "\n",
    "gs_cv_lr = GridSearchCV(pipe_cv_lr, param_grid=pipe_cv_lr_params, cv=3)\n",
    "\n",
    "gs_cv_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ead275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_cv_lr_train = gs_cv_lr.predict(X_train)\n",
    "y_pred_cv_lr = gs_cv_lr.predict(X_test)\n",
    "y_pred_proba_cv_lr = gs_cv_lr.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e15c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "pred_prob_train = gs_cv_lr.predict_proba(X_train)\n",
    "auc_score_train = roc_auc_score(y_train, pred_prob_train, \n",
    "                                multi_class=\"ovr\", average=\"micro\")\n",
    "pred_prob_test = gs_cv_lr.predict_proba(X_test)\n",
    "auc_score_test = roc_auc_score(y_test, pred_prob_test, \n",
    "                                multi_class=\"ovr\", average=\"micro\")\n",
    "\n",
    "print(f'ROC-AUC on training set: {auc_score_train}')\n",
    "print(f'ROC-AUC on testing set: {auc_score_test}')\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_cv_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.set_index(['10 Tropes'])['text_lemma'].str.split().apply(lambda x:  pd.Series([' '.join(x[i:i+ (len(x)//30)]) \n",
    "                                                                                         for i in range(0, len(x), len(x)//30)])).stack().reset_index().drop('level_1', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = ['Trope Name', 'text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf6ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = test_df['text_lemma']\n",
    "y = test_df['Trope Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f'The X train set is {X_train.shape[0]} rows long.')\n",
    "print(f'The y train set is {y_train.shape[0]} rows long.')\n",
    "print(f'The X test set is {X_test.shape[0]} rows long.')\n",
    "print(f'The y test set is {y_test.shape[0]} rows long.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Trope Name'] = test_df['Trope Name'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "binarised_df = pd.DataFrame(mlb.fit_transform(test_df['Trope Name']),columns=mlb.classes_, index=test_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32833bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binarised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d084c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.join(binarised_df).drop('Trope Name', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dddabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df['text_lemma']\n",
    "y = test_df.drop('text_lemma', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecbe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f'The X train set is {X_train.shape[0]} rows long.')\n",
    "print(f'The y train set is {y_train.shape[0]} rows long.')\n",
    "print(f'The X test set is {X_test.shape[0]} rows long.')\n",
    "print(f'The y test set is {y_test.shape[0]} rows long.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61859267",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cv_xgb = Pipeline(steps=[('cvec', CountVectorizer()),\n",
    "                              ('xgb', MultiOutputClassifier(estimator=XGBClassifier(booster = 'gblinear',\n",
    "                                                                                   eta = 0.05)))])\n",
    "\n",
    "pipe_cv_xgb_params = {'cvec__max_features':[5000], #2000, 3000, 4000, 5000\n",
    "                      'cvec__max_df':[.85], #.85, .90, .95\n",
    "                      'cvec__ngram_range':[(1,2)], #(1,1), (1,2), (1,3), (2,2)\n",
    "                     } \n",
    "\n",
    "gs_cv_xgb = GridSearchCV(pipe_cv_xgb, param_grid=pipe_cv_xgb_params, cv=3)\n",
    "\n",
    "gs_cv_xgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4979a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_cv_xgb_train = gs_cv_xgb.predict(X_train)\n",
    "y_pred_cv_xgb = gs_cv_xgb.predict(X_test)\n",
    "y_pred_proba_cv_xgb = gs_cv_xgb.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cv_xgb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_cv_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08983bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
