{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a31a06d",
   "metadata": {},
   "source": [
    "## 1. Imports (Libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec9113",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d09a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9330d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735f845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLP libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41890203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1a5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445a9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if not installed\n",
    "\n",
    "#!pip install scikit-multilearn\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bef4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45206534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if not installed\n",
    "\n",
    "#!pip install shap\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1924a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some display adjustments to account for the fact that we have many columns\n",
    "# and some columns contain many characters\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6e1cb",
   "metadata": {},
   "source": [
    "## 2. Imports (Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c234c",
   "metadata": {},
   "source": [
    "<a id='data_imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099aa819",
   "metadata": {},
   "source": [
    "Since we exported the cleaned dataset as a csv file in Part II, we can simply import that file and start working on it immediately. The two columns we are most concerned with are 'redditlabel' and 'text_lemma'.\n",
    "\n",
    "Data dictionary:\n",
    "\n",
    "For test_df:\n",
    "|column| datatype|explanation|\n",
    "|:-|:-:|:-|\n",
    "|<b>Episode Title</b>|*object*| The subject title for each episode for the first season of the Simpsons.|\n",
    "|<b>Full Story</b>| *object*| The subject title of the Reddit post.|\n",
    "|<b>text_lemma</b>| *object*| The subject title of the Reddit post.|\n",
    "|<b>10 Tropes</b>| *object*| The subject title of the Reddit post.|\n",
    "<br>\n",
    "\n",
    "For train_df:\n",
    "|column| datatype|explanation|\n",
    "|:-|:-:|:-|\n",
    "|<b>Trope Name</b>|*object*| The name for each trope.|\n",
    "|<b>Trope Description</b>| *object*| The description of each trope (e.g. What is the trope about?).|\n",
    "|<b>Text Length</b>| *int64*| Description word length.|\n",
    "|<b>text_lemma</b>| *object*| Trope Description after applying the lemmization of Trope Description.|\n",
    "<br>\n",
    "\n",
    "For binarised_df:\n",
    "|column| datatype|explanation|\n",
    "|:-|:-:|:-|\n",
    "|<b>Catchphrase</b>|*int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Characterization Marches On</b>| *int32*| The description of each trope (e.g. What is the trope about?).|\n",
    "|<b>Comically Missing the Point</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Couch Gag</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Disproportionate Retribution</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Establishing Character Moment</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Imagine Spot</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Karma Houdini</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Running Gag</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "|<b>Special Guest</b>| *int32*| Binary column (1 = Present in text, 0 = Absent in text)|\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b07b7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('simpsons_10_tropes.csv')\n",
    "train_df = pd.read_csv('10_tropes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d3f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Full Story</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>10 Tropes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simpsons Roasting on an Open Fire</td>\n",
       "      <td>Homer hastily drives the Family Sedan with Marge and Maggie through a snowcovered street They ar...</td>\n",
       "      <td>homer hastily drive the family sedan with marge and maggie through a snowcovered street they be ...</td>\n",
       "      <td>['Running Gag', 'Establishing Character Moment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bart the Genius</td>\n",
       "      <td>The Simpson family is playing Scrabble in the living room in an effort to build Bart’s vocabular...</td>\n",
       "      <td>the simpson family be play scrabble in the living room in an effort to build bart ’ s vocabulary...</td>\n",
       "      <td>['Imagine Spot', 'Comically Missing the Point', 'Couch Gag', 'Establishing Character Moment', 'C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Homers Odyssey</td>\n",
       "      <td>The episode begins in front of Springfield Elementary as Mrs Krabappel rounds up her class inclu...</td>\n",
       "      <td>the episode begin in front of springfield elementary a mr krabappel round up her class include b...</td>\n",
       "      <td>['Karma Houdini', 'Characterization Marches On', 'Comically Missing the Point', 'Couch Gag', 'Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theres No Disgrace Like Home</td>\n",
       "      <td>Bart and Lisa are fighting but it is not long until Homer quickly rushes in to break the melee u...</td>\n",
       "      <td>bart and lisa be fight but it be not long until homer quickly rush in to break the melee up he t...</td>\n",
       "      <td>['Imagine Spot', 'Characterization Marches On', 'Disproportionate Retribution', 'Comically Missi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bart the General</td>\n",
       "      <td>Bart and Lisa fight over Lisas cupcakesThe episode begins inside the Simpsons kitchen where Lisa...</td>\n",
       "      <td>bart and lisa fight over lisas cupcakesthe episode begin inside the simpson kitchen where lisa b...</td>\n",
       "      <td>['Imagine Spot', 'Characterization Marches On', 'Disproportionate Retribution', 'Couch Gag', 'Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Moaning Lisa</td>\n",
       "      <td>Lisa feels depressedThe episode starts with a melancholic Lisa staring at herself in the bathroo...</td>\n",
       "      <td>lisa feel depressedthe episode start with a melancholic lisa star at herself in the bathroom mir...</td>\n",
       "      <td>['Characterization Marches On', 'Comically Missing the Point', 'Couch Gag', 'Special Guest']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Call of the Simpsons</td>\n",
       "      <td>The episode begins with Homer and Bart outside doing yard work when Ned Flanders pulls up in his...</td>\n",
       "      <td>the episode begin with homer and bart outside do yard work when ned flanders pull up in his bran...</td>\n",
       "      <td>['Comically Missing the Point', 'Couch Gag', 'Special Guest']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Telltale Head</td>\n",
       "      <td>Homer and Bart being chased by the mobThe episode begins with Homer and Bart walking on a sidewa...</td>\n",
       "      <td>homer and bart be chase by the mobthe episode begin with homer and bart walk on a sidewalk in do...</td>\n",
       "      <td>['Couch Gag']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Life on the Fast Lane</td>\n",
       "      <td>It is Marges birthday so Bart and Lisa prepare breakfast in bed for her During the surprise Home...</td>\n",
       "      <td>it be marge birthday so bart and lisa prepare breakfast in bed for her during the surprise homer...</td>\n",
       "      <td>['Couch Gag', 'Special Guest', 'Establishing Character Moment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Homers Night Out</td>\n",
       "      <td>Bart purchases a miniature spy camera from a mailorder catalog which arrives six months later Ba...</td>\n",
       "      <td>bart purchase a miniature spy camera from a mailorder catalog which arrives six month later bart...</td>\n",
       "      <td>['Karma Houdini', 'Comically Missing the Point', 'Couch Gag', 'Special Guest']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Crepes of Wrath</td>\n",
       "      <td>Having being forced to clean his room after accidentally causing Homer to trip and fall down the...</td>\n",
       "      <td>have be force to clean his room after accidentally cause homer to trip and fall down the stair t...</td>\n",
       "      <td>['Karma Houdini', 'Disproportionate Retribution', 'Comically Missing the Point', 'Couch Gag']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Krusty Gets Busted</td>\n",
       "      <td>Krusty the Clown threatening Apu at gunpointThe episode begins with Bart Lisa and Maggie watchin...</td>\n",
       "      <td>krusty the clown threaten apu at gunpointthe episode begin with bart lisa and maggie watch krust...</td>\n",
       "      <td>['Characterization Marches On', 'Disproportionate Retribution', 'Couch Gag', 'Special Guest', 'K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Some Enchanted Evening</td>\n",
       "      <td>On a Friday morning the Simpson family are eating breakfast together Lisa and Bart have a tugofw...</td>\n",
       "      <td>on a friday morning the simpson family be eat breakfast together lisa and bart have a tugofwar o...</td>\n",
       "      <td>['Karma Houdini', 'Characterization Marches On', 'Disproportionate Retribution', 'Couch Gag', 'S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Episode Title  \\\n",
       "0   Simpsons Roasting on an Open Fire   \n",
       "1                     Bart the Genius   \n",
       "2                      Homers Odyssey   \n",
       "3        Theres No Disgrace Like Home   \n",
       "4                    Bart the General   \n",
       "5                        Moaning Lisa   \n",
       "6            The Call of the Simpsons   \n",
       "7                   The Telltale Head   \n",
       "8               Life on the Fast Lane   \n",
       "9                    Homers Night Out   \n",
       "10                The Crepes of Wrath   \n",
       "11                 Krusty Gets Busted   \n",
       "12             Some Enchanted Evening   \n",
       "\n",
       "                                                                                             Full Story  \\\n",
       "0   Homer hastily drives the Family Sedan with Marge and Maggie through a snowcovered street They ar...   \n",
       "1   The Simpson family is playing Scrabble in the living room in an effort to build Bart’s vocabular...   \n",
       "2   The episode begins in front of Springfield Elementary as Mrs Krabappel rounds up her class inclu...   \n",
       "3   Bart and Lisa are fighting but it is not long until Homer quickly rushes in to break the melee u...   \n",
       "4   Bart and Lisa fight over Lisas cupcakesThe episode begins inside the Simpsons kitchen where Lisa...   \n",
       "5   Lisa feels depressedThe episode starts with a melancholic Lisa staring at herself in the bathroo...   \n",
       "6   The episode begins with Homer and Bart outside doing yard work when Ned Flanders pulls up in his...   \n",
       "7   Homer and Bart being chased by the mobThe episode begins with Homer and Bart walking on a sidewa...   \n",
       "8   It is Marges birthday so Bart and Lisa prepare breakfast in bed for her During the surprise Home...   \n",
       "9   Bart purchases a miniature spy camera from a mailorder catalog which arrives six months later Ba...   \n",
       "10  Having being forced to clean his room after accidentally causing Homer to trip and fall down the...   \n",
       "11  Krusty the Clown threatening Apu at gunpointThe episode begins with Bart Lisa and Maggie watchin...   \n",
       "12  On a Friday morning the Simpson family are eating breakfast together Lisa and Bart have a tugofw...   \n",
       "\n",
       "                                                                                             text_lemma  \\\n",
       "0   homer hastily drive the family sedan with marge and maggie through a snowcovered street they be ...   \n",
       "1   the simpson family be play scrabble in the living room in an effort to build bart ’ s vocabulary...   \n",
       "2   the episode begin in front of springfield elementary a mr krabappel round up her class include b...   \n",
       "3   bart and lisa be fight but it be not long until homer quickly rush in to break the melee up he t...   \n",
       "4   bart and lisa fight over lisas cupcakesthe episode begin inside the simpson kitchen where lisa b...   \n",
       "5   lisa feel depressedthe episode start with a melancholic lisa star at herself in the bathroom mir...   \n",
       "6   the episode begin with homer and bart outside do yard work when ned flanders pull up in his bran...   \n",
       "7   homer and bart be chase by the mobthe episode begin with homer and bart walk on a sidewalk in do...   \n",
       "8   it be marge birthday so bart and lisa prepare breakfast in bed for her during the surprise homer...   \n",
       "9   bart purchase a miniature spy camera from a mailorder catalog which arrives six month later bart...   \n",
       "10  have be force to clean his room after accidentally cause homer to trip and fall down the stair t...   \n",
       "11  krusty the clown threaten apu at gunpointthe episode begin with bart lisa and maggie watch krust...   \n",
       "12  on a friday morning the simpson family be eat breakfast together lisa and bart have a tugofwar o...   \n",
       "\n",
       "                                                                                              10 Tropes  \n",
       "0                                                      ['Running Gag', 'Establishing Character Moment']  \n",
       "1   ['Imagine Spot', 'Comically Missing the Point', 'Couch Gag', 'Establishing Character Moment', 'C...  \n",
       "2   ['Karma Houdini', 'Characterization Marches On', 'Comically Missing the Point', 'Couch Gag', 'Sp...  \n",
       "3   ['Imagine Spot', 'Characterization Marches On', 'Disproportionate Retribution', 'Comically Missi...  \n",
       "4   ['Imagine Spot', 'Characterization Marches On', 'Disproportionate Retribution', 'Couch Gag', 'Ru...  \n",
       "5          ['Characterization Marches On', 'Comically Missing the Point', 'Couch Gag', 'Special Guest']  \n",
       "6                                         ['Comically Missing the Point', 'Couch Gag', 'Special Guest']  \n",
       "7                                                                                         ['Couch Gag']  \n",
       "8                                       ['Couch Gag', 'Special Guest', 'Establishing Character Moment']  \n",
       "9                        ['Karma Houdini', 'Comically Missing the Point', 'Couch Gag', 'Special Guest']  \n",
       "10        ['Karma Houdini', 'Disproportionate Retribution', 'Comically Missing the Point', 'Couch Gag']  \n",
       "11  ['Characterization Marches On', 'Disproportionate Retribution', 'Couch Gag', 'Special Guest', 'K...  \n",
       "12  ['Karma Houdini', 'Characterization Marches On', 'Disproportionate Retribution', 'Couch Gag', 'S...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57028693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Episode Title    object\n",
       "Full Story       object\n",
       "text_lemma       object\n",
       "10 Tropes        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b78df6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trope Name</th>\n",
       "      <th>Trope Description</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imagine Spot</td>\n",
       "      <td>Okay Ralphie You win this time But well be backElliot JD be sensitive Dont act like youre at a ...</td>\n",
       "      <td>917</td>\n",
       "      <td>okay ralphie you win this time but well be backelliot jd be sensitive dont act like youre at a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Couch Gag</td>\n",
       "      <td>After seven seasons weve pretty much said everything you can say in this spot— Garfield Garfield...</td>\n",
       "      <td>864</td>\n",
       "      <td>after seven season weve pretty much say everything you can say in this spot— garfield garfield a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catchphrase</td>\n",
       "      <td>Catchphrase may refer to one of the following Character Catchphrase A phrase a character repeats...</td>\n",
       "      <td>642</td>\n",
       "      <td>catchphrase may refer to one of the follow character catchphrase a phrase a character repeat mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comically Missing the Point</td>\n",
       "      <td>I started to walk down the street when I heard a voice saying Good evening Mr Dowd I turned and ...</td>\n",
       "      <td>1507</td>\n",
       "      <td>i start to walk down the street when i heard a voice say good even mr dowd i turn and there be t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Running Gag</td>\n",
       "      <td>Thats not a running gag Thats a pun Its a running gag nowKermit the Frog No Fozzie Do not answer...</td>\n",
       "      <td>1633</td>\n",
       "      <td>thats not a run gag thats a pun it a run gag nowkermit the frog no fozzie do not answer that tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Disproportionate Retribution</td>\n",
       "      <td>But that was two years agoRevenge is a dish best served with an extra helping— Captain Young Tro...</td>\n",
       "      <td>2243</td>\n",
       "      <td>but that be two year agorevenge be a dish best serve with an extra helping— captain young troop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Establishing Character Moment</td>\n",
       "      <td>In just a handful of scenes weve established the full set of character archetypes to see us thro...</td>\n",
       "      <td>2597</td>\n",
       "      <td>in just a handful of scene weve establish the full set of character archetype to see u through u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Karma Houdini</td>\n",
       "      <td>So is Satan just generous when people dont have a soul to sell Maybe if you do enough deeds in h...</td>\n",
       "      <td>5204</td>\n",
       "      <td>so be satan just generous when people dont have a soul to sell maybe if you do enough deed in hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Characterization Marches On</td>\n",
       "      <td>Nothing reconciles a past of animal abuse better than donut partiesAoi Asahina What the hecks ha...</td>\n",
       "      <td>1872</td>\n",
       "      <td>nothing reconciles a past of animal abuse well than donut partiesaoi asahina what the hecks happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Special Guest</td>\n",
       "      <td>Special but unknown guest starnote How can you have a guest star in a movieLadies and Gentlemen ...</td>\n",
       "      <td>728</td>\n",
       "      <td>special but unknown guest starnote how can you have a guest star in a movieladies and gentleman ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Trope Name  \\\n",
       "0                   Imagine Spot   \n",
       "1                      Couch Gag   \n",
       "2                    Catchphrase   \n",
       "3    Comically Missing the Point   \n",
       "4                    Running Gag   \n",
       "5   Disproportionate Retribution   \n",
       "6  Establishing Character Moment   \n",
       "7                  Karma Houdini   \n",
       "8    Characterization Marches On   \n",
       "9                  Special Guest   \n",
       "\n",
       "                                                                                     Trope Description  \\\n",
       "0   Okay Ralphie You win this time But well be backElliot JD be sensitive Dont act like youre at a ...   \n",
       "1  After seven seasons weve pretty much said everything you can say in this spot— Garfield Garfield...   \n",
       "2  Catchphrase may refer to one of the following Character Catchphrase A phrase a character repeats...   \n",
       "3  I started to walk down the street when I heard a voice saying Good evening Mr Dowd I turned and ...   \n",
       "4  Thats not a running gag Thats a pun Its a running gag nowKermit the Frog No Fozzie Do not answer...   \n",
       "5  But that was two years agoRevenge is a dish best served with an extra helping— Captain Young Tro...   \n",
       "6  In just a handful of scenes weve established the full set of character archetypes to see us thro...   \n",
       "7  So is Satan just generous when people dont have a soul to sell Maybe if you do enough deeds in h...   \n",
       "8  Nothing reconciles a past of animal abuse better than donut partiesAoi Asahina What the hecks ha...   \n",
       "9  Special but unknown guest starnote How can you have a guest star in a movieLadies and Gentlemen ...   \n",
       "\n",
       "   Text Length  \\\n",
       "0          917   \n",
       "1          864   \n",
       "2          642   \n",
       "3         1507   \n",
       "4         1633   \n",
       "5         2243   \n",
       "6         2597   \n",
       "7         5204   \n",
       "8         1872   \n",
       "9          728   \n",
       "\n",
       "                                                                                            text_lemma  \n",
       "0  okay ralphie you win this time but well be backelliot jd be sensitive dont act like youre at a p...  \n",
       "1  after seven season weve pretty much say everything you can say in this spot— garfield garfield a...  \n",
       "2  catchphrase may refer to one of the follow character catchphrase a phrase a character repeat mul...  \n",
       "3  i start to walk down the street when i heard a voice say good even mr dowd i turn and there be t...  \n",
       "4  thats not a run gag thats a pun it a run gag nowkermit the frog no fozzie do not answer that tel...  \n",
       "5  but that be two year agorevenge be a dish best serve with an extra helping— captain young troop ...  \n",
       "6  in just a handful of scene weve establish the full set of character archetype to see u through u...  \n",
       "7  so be satan just generous when people dont have a soul to sell maybe if you do enough deed in hi...  \n",
       "8  nothing reconciles a past of animal abuse well than donut partiesaoi asahina what the hecks happ...  \n",
       "9  special but unknown guest starnote how can you have a guest star in a movieladies and gentleman ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67d55bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trope Name           object\n",
       "Trope Description    object\n",
       "Text Length           int64\n",
       "text_lemma           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8271c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.set_index(['Trope Name'])['text_lemma'].str.split().apply(lambda x:  pd.Series([' '.join(x[i:i+ (len(x)//30)]) \n",
    "                                                                                         for i in range(0, len(x), len(x)//30)])).stack().reset_index().drop('level_1', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02ed19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6aac2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['Trope Name', 'text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f25d5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = train_df['text_lemma']\n",
    "y = train_df['Trope Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1efea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X train set is 256 rows long.\n",
      "The y train set is 256 rows long.\n",
      "The X test set is 64 rows long.\n",
      "The y test set is 64 rows long.\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f'The X train set is {X_train.shape[0]} rows long.')\n",
    "print(f'The y train set is {y_train.shape[0]} rows long.')\n",
    "print(f'The X test set is {X_test.shape[0]} rows long.')\n",
    "print(f'The y test set is {y_test.shape[0]} rows long.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474f3b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.85], &#x27;cvec__max_features&#x27;: [5000],\n",
       "                         &#x27;cvec__min_df&#x27;: [3], &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;logreg__C&#x27;: [0.1], &#x27;logreg__penalty&#x27;: [&#x27;l2&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.85], &#x27;cvec__max_features&#x27;: [5000],\n",
       "                         &#x27;cvec__min_df&#x27;: [3], &#x27;cvec__ngram_range&#x27;: [(1, 2)],\n",
       "                         &#x27;logreg__C&#x27;: [0.1], &#x27;logreg__penalty&#x27;: [&#x27;l2&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(solver='liblinear'))]),\n",
       "             param_grid={'cvec__max_df': [0.85], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [3], 'cvec__ngram_range': [(1, 2)],\n",
       "                         'logreg__C': [0.1], 'logreg__penalty': ['l2']})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "pipe_cv_lr = Pipeline(steps=[('cvec', CountVectorizer()),\n",
    "                               ('logreg', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "pipe_cv_lr_params = {'cvec__max_features':[5000], #2000, 3000, 4000, 5000\n",
    "                       'cvec__min_df':[3], #2, 3\n",
    "                       'cvec__max_df':[.85], #.85, .90, .95\n",
    "                       'cvec__ngram_range':[(1,2)], #(1,1), (1,2), (1,3), (2,2)\n",
    "                       'logreg__C': [0.1], #0.05, 0.1, 1\n",
    "                       'logreg__penalty': ['l2']} #'l1', 'l2'\n",
    "\n",
    "gs_cv_lr = GridSearchCV(pipe_cv_lr, param_grid=pipe_cv_lr_params, cv=3)\n",
    "\n",
    "gs_cv_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10ead275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_cv_lr_train = gs_cv_lr.predict(X_train)\n",
    "y_pred_cv_lr = gs_cv_lr.predict(X_test)\n",
    "y_pred_proba_cv_lr = gs_cv_lr.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d4e15c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC on training set: 0.9496053059895834\n",
      "ROC-AUC on testing set: 0.7713487413194444\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "                  Catchphrase       1.00      0.17      0.29         6\n",
      "  Characterization Marches On       0.00      0.00      0.00         7\n",
      "  Comically Missing the Point       0.00      0.00      0.00         7\n",
      "                    Couch Gag       0.25      0.50      0.33         8\n",
      " Disproportionate Retribution       0.33      0.17      0.22         6\n",
      "Establishing Character Moment       0.25      0.17      0.20         6\n",
      "                 Imagine Spot       0.00      0.00      0.00         6\n",
      "                Karma Houdini       0.35      1.00      0.52         6\n",
      "                  Running Gag       0.50      0.67      0.57         6\n",
      "                Special Guest       0.60      0.50      0.55         6\n",
      "\n",
      "                     accuracy                           0.31        64\n",
      "                    macro avg       0.33      0.32      0.27        64\n",
      "                 weighted avg       0.32      0.31      0.26        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "pred_prob_train = gs_cv_lr.predict_proba(X_train)\n",
    "auc_score_train = roc_auc_score(y_train, pred_prob_train, \n",
    "                                multi_class=\"ovr\", average=\"micro\")\n",
    "pred_prob_test = gs_cv_lr.predict_proba(X_test)\n",
    "auc_score_test = roc_auc_score(y_test, pred_prob_test, \n",
    "                                multi_class=\"ovr\", average=\"micro\")\n",
    "\n",
    "print(f'ROC-AUC on training set: {auc_score_train}')\n",
    "print(f'ROC-AUC on testing set: {auc_score_test}')\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_cv_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4b7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.set_index(['10 Tropes'])['text_lemma'].str.split().apply(lambda x:  pd.Series([' '.join(x[i:i+ (len(x)//30)]) \n",
    "                                                                                         for i in range(0, len(x), len(x)//30)])).stack().reset_index().drop('level_1', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6a4cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = ['Trope Name', 'text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48bf6ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = test_df['text_lemma']\n",
    "y = test_df['Trope Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a98fb964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X train set is 324 rows long.\n",
      "The y train set is 324 rows long.\n",
      "The X test set is 81 rows long.\n",
      "The y test set is 81 rows long.\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f'The X train set is {X_train.shape[0]} rows long.')\n",
    "print(f'The y train set is {y_train.shape[0]} rows long.')\n",
    "print(f'The X test set is {X_test.shape[0]} rows long.')\n",
    "print(f'The y test set is {y_test.shape[0]} rows long.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38fa2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Trope Name'] = test_df['Trope Name'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7460ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "binarised_df = pd.DataFrame(mlb.fit_transform(test_df['Trope Name']),columns=mlb.classes_, index=test_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32833bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Catchphrase</th>\n",
       "      <th>Characterization Marches On</th>\n",
       "      <th>Comically Missing the Point</th>\n",
       "      <th>Couch Gag</th>\n",
       "      <th>Disproportionate Retribution</th>\n",
       "      <th>Establishing Character Moment</th>\n",
       "      <th>Imagine Spot</th>\n",
       "      <th>Karma Houdini</th>\n",
       "      <th>Running Gag</th>\n",
       "      <th>Special Guest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Catchphrase  Characterization Marches On  Comically Missing the Point  \\\n",
       "0              0                            0                            0   \n",
       "1              0                            0                            0   \n",
       "2              0                            0                            0   \n",
       "3              0                            0                            0   \n",
       "4              0                            0                            0   \n",
       "..           ...                          ...                          ...   \n",
       "400            0                            1                            0   \n",
       "401            0                            1                            0   \n",
       "402            0                            1                            0   \n",
       "403            0                            1                            0   \n",
       "404            0                            1                            0   \n",
       "\n",
       "     Couch Gag  Disproportionate Retribution  Establishing Character Moment  \\\n",
       "0            0                             0                              1   \n",
       "1            0                             0                              1   \n",
       "2            0                             0                              1   \n",
       "3            0                             0                              1   \n",
       "4            0                             0                              1   \n",
       "..         ...                           ...                            ...   \n",
       "400          1                             1                              1   \n",
       "401          1                             1                              1   \n",
       "402          1                             1                              1   \n",
       "403          1                             1                              1   \n",
       "404          1                             1                              1   \n",
       "\n",
       "     Imagine Spot  Karma Houdini  Running Gag  Special Guest  \n",
       "0               0              0            1              0  \n",
       "1               0              0            1              0  \n",
       "2               0              0            1              0  \n",
       "3               0              0            1              0  \n",
       "4               0              0            1              0  \n",
       "..            ...            ...          ...            ...  \n",
       "400             0              1            0              1  \n",
       "401             0              1            0              1  \n",
       "402             0              1            0              1  \n",
       "403             0              1            0              1  \n",
       "404             0              1            0              1  \n",
       "\n",
       "[405 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9313e7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catchphrase                      int32\n",
       "Characterization Marches On      int32\n",
       "Comically Missing the Point      int32\n",
       "Couch Gag                        int32\n",
       "Disproportionate Retribution     int32\n",
       "Establishing Character Moment    int32\n",
       "Imagine Spot                     int32\n",
       "Karma Houdini                    int32\n",
       "Running Gag                      int32\n",
       "Special Guest                    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarised_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d084c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.join(binarised_df).drop('Trope Name', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fefb7041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>Catchphrase</th>\n",
       "      <th>Characterization Marches On</th>\n",
       "      <th>Comically Missing the Point</th>\n",
       "      <th>Couch Gag</th>\n",
       "      <th>Disproportionate Retribution</th>\n",
       "      <th>Establishing Character Moment</th>\n",
       "      <th>Imagine Spot</th>\n",
       "      <th>Karma Houdini</th>\n",
       "      <th>Running Gag</th>\n",
       "      <th>Special Guest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homer hastily drive the family sedan with marge and maggie through a snowcovered street they be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tawanga the santa claus of the south sea lisa ’ s dance cause awe throughout the crowd lisa perf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a disappointed look for bart action but a the pageant continue he grows bore and wonder aloud ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and lisa show marge their wish list marge be uncomfortable when lisa once again asks for a pony ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with him request marge a grumble homer hand the phone over to marge and the two sister discus th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            text_lemma  \\\n",
       "0  homer hastily drive the family sedan with marge and maggie through a snowcovered street they be ...   \n",
       "1  tawanga the santa claus of the south sea lisa ’ s dance cause awe throughout the crowd lisa perf...   \n",
       "2  a disappointed look for bart action but a the pageant continue he grows bore and wonder aloud ho...   \n",
       "3  and lisa show marge their wish list marge be uncomfortable when lisa once again asks for a pony ...   \n",
       "4  with him request marge a grumble homer hand the phone over to marge and the two sister discus th...   \n",
       "\n",
       "   Catchphrase  Characterization Marches On  Comically Missing the Point  \\\n",
       "0            0                            0                            0   \n",
       "1            0                            0                            0   \n",
       "2            0                            0                            0   \n",
       "3            0                            0                            0   \n",
       "4            0                            0                            0   \n",
       "\n",
       "   Couch Gag  Disproportionate Retribution  Establishing Character Moment  \\\n",
       "0          0                             0                              1   \n",
       "1          0                             0                              1   \n",
       "2          0                             0                              1   \n",
       "3          0                             0                              1   \n",
       "4          0                             0                              1   \n",
       "\n",
       "   Imagine Spot  Karma Houdini  Running Gag  Special Guest  \n",
       "0             0              0            1              0  \n",
       "1             0              0            1              0  \n",
       "2             0              0            1              0  \n",
       "3             0              0            1              0  \n",
       "4             0              0            1              0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dddabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df['text_lemma']\n",
    "y = test_df.drop('text_lemma', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cecbe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X train set is 324 rows long.\n",
      "The y train set is 324 rows long.\n",
      "The X test set is 81 rows long.\n",
      "The y test set is 81 rows long.\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f'The X train set is {X_train.shape[0]} rows long.')\n",
    "print(f'The y train set is {y_train.shape[0]} rows long.')\n",
    "print(f'The X test set is {X_test.shape[0]} rows long.')\n",
    "print(f'The y test set is {y_test.shape[0]} rows long.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61859267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                                                      booster=&#x27;gblinear&#x27;,\n",
       "                                                                                      callbacks=None,\n",
       "                                                                                      colsample_bylevel=None,\n",
       "                                                                                      colsample_bynode=None,\n",
       "                                                                                      colsample_bytree=None,\n",
       "                                                                                      device=None,\n",
       "                                                                                      early_stopping_rounds=None,\n",
       "                                                                                      enable_categorical=False,\n",
       "                                                                                      eta=0.05,\n",
       "                                                                                      eval_metric=None,\n",
       "                                                                                      feature_types=None,...\n",
       "                                                                                      learning_rate=None,\n",
       "                                                                                      max_bin=None,\n",
       "                                                                                      max_cat_threshold=None,\n",
       "                                                                                      max_cat_to_onehot=None,\n",
       "                                                                                      max_delta_step=None,\n",
       "                                                                                      max_depth=None,\n",
       "                                                                                      max_leaves=None,\n",
       "                                                                                      min_child_weight=None,\n",
       "                                                                                      missing=nan,\n",
       "                                                                                      monotone_constraints=None,\n",
       "                                                                                      multi_strategy=None,\n",
       "                                                                                      n_estimators=None,\n",
       "                                                                                      n_jobs=None,\n",
       "                                                                                      num_parallel_tree=None, ...)))]),\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.85], &#x27;cvec__max_features&#x27;: [5000],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                                                      booster=&#x27;gblinear&#x27;,\n",
       "                                                                                      callbacks=None,\n",
       "                                                                                      colsample_bylevel=None,\n",
       "                                                                                      colsample_bynode=None,\n",
       "                                                                                      colsample_bytree=None,\n",
       "                                                                                      device=None,\n",
       "                                                                                      early_stopping_rounds=None,\n",
       "                                                                                      enable_categorical=False,\n",
       "                                                                                      eta=0.05,\n",
       "                                                                                      eval_metric=None,\n",
       "                                                                                      feature_types=None,...\n",
       "                                                                                      learning_rate=None,\n",
       "                                                                                      max_bin=None,\n",
       "                                                                                      max_cat_threshold=None,\n",
       "                                                                                      max_cat_to_onehot=None,\n",
       "                                                                                      max_delta_step=None,\n",
       "                                                                                      max_depth=None,\n",
       "                                                                                      max_leaves=None,\n",
       "                                                                                      min_child_weight=None,\n",
       "                                                                                      missing=nan,\n",
       "                                                                                      monotone_constraints=None,\n",
       "                                                                                      multi_strategy=None,\n",
       "                                                                                      n_estimators=None,\n",
       "                                                                                      n_jobs=None,\n",
       "                                                                                      num_parallel_tree=None, ...)))]),\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.85], &#x27;cvec__max_features&#x27;: [5000],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 2)]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                               booster=&#x27;gblinear&#x27;,\n",
       "                                                               callbacks=None,\n",
       "                                                               colsample_bylevel=None,\n",
       "                                                               colsample_bynode=None,\n",
       "                                                               colsample_bytree=None,\n",
       "                                                               device=None,\n",
       "                                                               early_stopping_rounds=None,\n",
       "                                                               enable_categorical=False,\n",
       "                                                               eta=0.05,\n",
       "                                                               eval_metric=None,\n",
       "                                                               feature_types=None,\n",
       "                                                               gamma=None,\n",
       "                                                               grow_policy=None,\n",
       "                                                               importance_type=None,\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=None,\n",
       "                                                               max_bin=None,\n",
       "                                                               max_cat_threshold=None,\n",
       "                                                               max_cat_to_onehot=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_depth=None,\n",
       "                                                               max_leaves=None,\n",
       "                                                               min_child_weight=None,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints=None,\n",
       "                                                               multi_strategy=None,\n",
       "                                                               n_estimators=None,\n",
       "                                                               n_jobs=None,\n",
       "                                                               num_parallel_tree=None, ...)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">xgb: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                              booster=&#x27;gblinear&#x27;,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eta=0.05, eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.05, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.05, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('xgb',\n",
       "                                        MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                                                      booster='gblinear',\n",
       "                                                                                      callbacks=None,\n",
       "                                                                                      colsample_bylevel=None,\n",
       "                                                                                      colsample_bynode=None,\n",
       "                                                                                      colsample_bytree=None,\n",
       "                                                                                      device=None,\n",
       "                                                                                      early_stopping_rounds=None,\n",
       "                                                                                      enable_categorical=False,\n",
       "                                                                                      eta=0.05,\n",
       "                                                                                      eval_metric=None,\n",
       "                                                                                      feature_types=None,...\n",
       "                                                                                      learning_rate=None,\n",
       "                                                                                      max_bin=None,\n",
       "                                                                                      max_cat_threshold=None,\n",
       "                                                                                      max_cat_to_onehot=None,\n",
       "                                                                                      max_delta_step=None,\n",
       "                                                                                      max_depth=None,\n",
       "                                                                                      max_leaves=None,\n",
       "                                                                                      min_child_weight=None,\n",
       "                                                                                      missing=nan,\n",
       "                                                                                      monotone_constraints=None,\n",
       "                                                                                      multi_strategy=None,\n",
       "                                                                                      n_estimators=None,\n",
       "                                                                                      n_jobs=None,\n",
       "                                                                                      num_parallel_tree=None, ...)))]),\n",
       "             param_grid={'cvec__max_df': [0.85], 'cvec__max_features': [5000],\n",
       "                         'cvec__ngram_range': [(1, 2)]})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv_xgb = Pipeline(steps=[('cvec', CountVectorizer()),\n",
    "                              ('xgb', MultiOutputClassifier(estimator=XGBClassifier(booster = 'gblinear',\n",
    "                                                                                   eta = 0.05)))])\n",
    "\n",
    "pipe_cv_xgb_params = {'cvec__max_features':[5000], #2000, 3000, 4000, 5000\n",
    "                      'cvec__max_df':[.85], #.85, .90, .95\n",
    "                      'cvec__ngram_range':[(1,2)], #(1,1), (1,2), (1,3), (2,2)\n",
    "                     } \n",
    "\n",
    "gs_cv_xgb = GridSearchCV(pipe_cv_xgb, param_grid=pipe_cv_xgb_params, cv=3)\n",
    "\n",
    "gs_cv_xgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c4979a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_cv_xgb_train = gs_cv_xgb.predict(X_train)\n",
    "y_pred_cv_xgb = gs_cv_xgb.predict(X_test)\n",
    "y_pred_proba_cv_xgb = gs_cv_xgb.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7648e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv_xgb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e710e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.28      0.42        18\n",
      "           1       0.81      0.59      0.69        37\n",
      "           2       0.75      0.80      0.77        45\n",
      "           3       0.93      1.00      0.96        75\n",
      "           4       0.80      0.77      0.79        31\n",
      "           5       0.86      0.25      0.39        24\n",
      "           6       1.00      0.33      0.50        18\n",
      "           7       0.76      0.69      0.72        32\n",
      "           8       1.00      0.33      0.50        18\n",
      "           9       0.90      0.80      0.84        44\n",
      "\n",
      "   micro avg       0.85      0.69      0.76       342\n",
      "   macro avg       0.86      0.58      0.66       342\n",
      "weighted avg       0.86      0.69      0.74       342\n",
      " samples avg       0.83      0.70      0.74       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_cv_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08983bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
